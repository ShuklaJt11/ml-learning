{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoders (Movie Recommender System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Importing dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('dataset/ml-1m/movies.dat', sep='::', header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('dataset/ml-1m/users.dat', sep='::', header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('dataset/ml-1m/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Creating the training and test set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('dataset/ml-100k/u1.base', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.array(pd.read_csv('dataset/ml-100k/u1.test', delimiter='\\t'), dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding total number of movies and users*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
    "total_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Converting data into movies as columns and users as rows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "  new_data = []\n",
    "  for id_users in range(1, total_users + 1):\n",
    "    id_movies = data[:, 1] [data[:, 0] == id_users]\n",
    "    id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
    "    ratings = np.zeros(total_movies)\n",
    "    ratings[id_movies - 1] = id_ratings\n",
    "    new_data.append(list(ratings))\n",
    "  return new_data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Converting data into torch tensors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set).cuda()\n",
    "test_set = torch.FloatTensor(test_set).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Creating Auto Encoder architecture and training it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedAutoEncoder (nn.Module):\n",
    "    def __init__(self, visible_nodes, hidden_nodes, activation_obj, ):\n",
    "        super(StackedAutoEncoder, self).__init__()\n",
    "        self.full_connection_1 = nn.Linear(visible_nodes, hidden_nodes[0])\n",
    "        self.full_connection_2 = nn.Linear(hidden_nodes[0], hidden_nodes[1])\n",
    "        self.full_connection_3 = nn.Linear(hidden_nodes[1], hidden_nodes[2])\n",
    "        self.full_connection_4 = nn.Linear(hidden_nodes[2], hidden_nodes[1])\n",
    "        self.full_connection_5 = nn.Linear(hidden_nodes[1], hidden_nodes[0])\n",
    "        self.full_connection_6 = nn.Linear(hidden_nodes[0], visible_nodes)\n",
    "        self.activation = activation_obj\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.full_connection_1(x))\n",
    "        x = self.activation(self.full_connection_2(x))\n",
    "        x = self.activation(self.full_connection_3(x))\n",
    "        x = self.activation(self.full_connection_4(x))\n",
    "        x = self.activation(self.full_connection_5(x))\n",
    "        x = self.full_connection_6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_nodes = total_movies\n",
    "hidden_nodes = [40, 20, 10]\n",
    "activation = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "StackedAutoEncoder(\n  (full_connection_1): Linear(in_features=1682, out_features=40, bias=True)\n  (full_connection_2): Linear(in_features=40, out_features=20, bias=True)\n  (full_connection_3): Linear(in_features=20, out_features=10, bias=True)\n  (full_connection_4): Linear(in_features=10, out_features=20, bias=True)\n  (full_connection_5): Linear(in_features=20, out_features=40, bias=True)\n  (full_connection_6): Linear(in_features=40, out_features=1682, bias=True)\n  (activation): Sigmoid()\n)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sae = StackedAutoEncoder(visible_nodes, hidden_nodes, activation)\n",
    "sae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch: 1 loss: 1.5488275838458894 star(s) out of 5\nepoch: 2 loss: 1.0750408583731579 star(s) out of 5\nepoch: 3 loss: 1.0560077350071018 star(s) out of 5\nepoch: 4 loss: 1.0495526581573273 star(s) out of 5\nepoch: 5 loss: 1.0475762864192593 star(s) out of 5\nepoch: 6 loss: 1.0442852473819553 star(s) out of 5\nepoch: 7 loss: 1.044380209905098 star(s) out of 5\nepoch: 8 loss: 1.0429923255580906 star(s) out of 5\nepoch: 9 loss: 1.0430915748804348 star(s) out of 5\nepoch: 10 loss: 1.0416671804259403 star(s) out of 5\nepoch: 11 loss: 1.0415199138304836 star(s) out of 5\nepoch: 12 loss: 1.0391496874563853 star(s) out of 5\nepoch: 13 loss: 1.0387104801419318 star(s) out of 5\nepoch: 14 loss: 1.0374491959206724 star(s) out of 5\nepoch: 15 loss: 1.0375545505694435 star(s) out of 5\nepoch: 16 loss: 1.035612345441371 star(s) out of 5\nepoch: 17 loss: 1.0354491157899632 star(s) out of 5\nepoch: 18 loss: 1.033688676401667 star(s) out of 5\nepoch: 19 loss: 1.032870619036821 star(s) out of 5\nepoch: 20 loss: 1.0332896769804616 star(s) out of 5\nepoch: 21 loss: 1.0319318121805572 star(s) out of 5\nepoch: 22 loss: 1.0312348560762234 star(s) out of 5\nepoch: 23 loss: 1.0301533453024525 star(s) out of 5\nepoch: 24 loss: 1.0297521775329568 star(s) out of 5\nepoch: 25 loss: 1.0296020664874168 star(s) out of 5\nepoch: 26 loss: 1.02840303943924 star(s) out of 5\nepoch: 27 loss: 1.028693270706832 star(s) out of 5\nepoch: 28 loss: 1.0272231598652428 star(s) out of 5\nepoch: 29 loss: 1.0269480284028876 star(s) out of 5\nepoch: 30 loss: 1.026036559001497 star(s) out of 5\nepoch: 31 loss: 1.026644788403191 star(s) out of 5\nepoch: 32 loss: 1.025132533321025 star(s) out of 5\nepoch: 33 loss: 1.0254202248131263 star(s) out of 5\nepoch: 34 loss: 1.0243455230987943 star(s) out of 5\nepoch: 35 loss: 1.0240818844457125 star(s) out of 5\nepoch: 36 loss: 1.0231936695285624 star(s) out of 5\nepoch: 37 loss: 1.0230965701888868 star(s) out of 5\nepoch: 38 loss: 1.0221435928584202 star(s) out of 5\nepoch: 39 loss: 1.022659677222036 star(s) out of 5\nepoch: 40 loss: 1.0211280917400285 star(s) out of 5\nepoch: 41 loss: 1.021581150227776 star(s) out of 5\nepoch: 42 loss: 1.0204325648490522 star(s) out of 5\nepoch: 43 loss: 1.020762820809685 star(s) out of 5\nepoch: 44 loss: 1.0192611997175807 star(s) out of 5\nepoch: 45 loss: 1.019557187624444 star(s) out of 5\nepoch: 46 loss: 1.01908973199531 star(s) out of 5\nepoch: 47 loss: 1.0190574142869 star(s) out of 5\nepoch: 48 loss: 1.0171562397713056 star(s) out of 5\nepoch: 49 loss: 1.0174968077042592 star(s) out of 5\nepoch: 50 loss: 1.0172761864041093 star(s) out of 5\nepoch: 51 loss: 1.0165658287194497 star(s) out of 5\nepoch: 52 loss: 1.0153454044408063 star(s) out of 5\nepoch: 53 loss: 1.0152118854892804 star(s) out of 5\nepoch: 54 loss: 1.014470441236726 star(s) out of 5\nepoch: 55 loss: 1.0131655232101056 star(s) out of 5\nepoch: 56 loss: 1.0151043671866227 star(s) out of 5\nepoch: 57 loss: 1.0114368045709312 star(s) out of 5\nepoch: 58 loss: 1.0159698532488544 star(s) out of 5\nepoch: 59 loss: 1.0106896238782943 star(s) out of 5\nepoch: 60 loss: 1.0134131574136784 star(s) out of 5\nepoch: 61 loss: 1.0088047874006743 star(s) out of 5\nepoch: 62 loss: 1.0108497660072482 star(s) out of 5\nepoch: 63 loss: 1.007758501755079 star(s) out of 5\nepoch: 64 loss: 1.0075104061195015 star(s) out of 5\nepoch: 65 loss: 1.0042616524369103 star(s) out of 5\nepoch: 66 loss: 1.0038517547276493 star(s) out of 5\nepoch: 67 loss: 1.000401109510618 star(s) out of 5\nepoch: 68 loss: 1.0017321181453858 star(s) out of 5\nepoch: 69 loss: 0.9987300831409949 star(s) out of 5\nepoch: 70 loss: 0.9999831439191099 star(s) out of 5\nepoch: 71 loss: 0.9981388652007327 star(s) out of 5\nepoch: 72 loss: 0.996783902233096 star(s) out of 5\nepoch: 73 loss: 0.9949869965412137 star(s) out of 5\nepoch: 74 loss: 0.9914707272977586 star(s) out of 5\nepoch: 75 loss: 0.9916038379786176 star(s) out of 5\nepoch: 76 loss: 0.9898246028851163 star(s) out of 5\nepoch: 77 loss: 0.987373690962145 star(s) out of 5\nepoch: 78 loss: 0.9866796476183296 star(s) out of 5\nepoch: 79 loss: 0.9843931435449914 star(s) out of 5\nepoch: 80 loss: 0.981665658509058 star(s) out of 5\nepoch: 81 loss: 0.9799837969664166 star(s) out of 5\nepoch: 82 loss: 0.979273552728926 star(s) out of 5\nepoch: 83 loss: 0.9773915120189594 star(s) out of 5\nepoch: 84 loss: 0.9755806589701737 star(s) out of 5\nepoch: 85 loss: 0.9744028757587107 star(s) out of 5\nepoch: 86 loss: 0.9725581978721636 star(s) out of 5\nepoch: 87 loss: 0.9722269513594436 star(s) out of 5\nepoch: 88 loss: 0.9706519174653301 star(s) out of 5\nepoch: 89 loss: 0.9688491617662344 star(s) out of 5\nepoch: 90 loss: 0.9687366952852555 star(s) out of 5\nepoch: 91 loss: 0.9673380373447142 star(s) out of 5\nepoch: 92 loss: 0.9664955340194731 star(s) out of 5\nepoch: 93 loss: 0.9641353821783931 star(s) out of 5\nepoch: 94 loss: 0.9649992905627117 star(s) out of 5\nepoch: 95 loss: 0.9671378515809672 star(s) out of 5\nepoch: 96 loss: 0.9641497046040388 star(s) out of 5\nepoch: 97 loss: 0.9633991888016324 star(s) out of 5\nepoch: 98 loss: 0.9620957131230877 star(s) out of 5\nepoch: 99 loss: 0.9618863745802815 star(s) out of 5\nepoch: 100 loss: 0.9598704401368415 star(s) out of 5\nepoch: 101 loss: 0.9597986350733716 star(s) out of 5\nepoch: 102 loss: 0.9579439492932235 star(s) out of 5\nepoch: 103 loss: 0.9581248518634716 star(s) out of 5\nepoch: 104 loss: 0.9562008238814178 star(s) out of 5\nepoch: 105 loss: 0.9569204534007542 star(s) out of 5\nepoch: 106 loss: 0.9544501970843327 star(s) out of 5\nepoch: 107 loss: 0.9550481639630494 star(s) out of 5\nepoch: 108 loss: 0.9528082029922667 star(s) out of 5\nepoch: 109 loss: 0.9539672568758362 star(s) out of 5\nepoch: 110 loss: 0.9511966126450491 star(s) out of 5\nepoch: 111 loss: 0.9528297965008086 star(s) out of 5\nepoch: 112 loss: 0.9501732300286565 star(s) out of 5\nepoch: 113 loss: 0.9516481069099056 star(s) out of 5\nepoch: 114 loss: 0.9484245331917266 star(s) out of 5\nepoch: 115 loss: 0.9499192132185302 star(s) out of 5\nepoch: 116 loss: 0.9472843547930705 star(s) out of 5\nepoch: 117 loss: 0.9493514003110303 star(s) out of 5\nepoch: 118 loss: 0.9462759358070189 star(s) out of 5\nepoch: 119 loss: 0.9489777143945325 star(s) out of 5\nepoch: 120 loss: 0.9462700354633097 star(s) out of 5\nepoch: 121 loss: 0.9476694895960625 star(s) out of 5\nepoch: 122 loss: 0.9448054834755586 star(s) out of 5\nepoch: 123 loss: 0.9467109375211221 star(s) out of 5\nepoch: 124 loss: 0.9435582741236165 star(s) out of 5\nepoch: 125 loss: 0.9456438646810846 star(s) out of 5\nepoch: 126 loss: 0.9426330310445505 star(s) out of 5\nepoch: 127 loss: 0.9440767950298408 star(s) out of 5\nepoch: 128 loss: 0.94186959178265 star(s) out of 5\nepoch: 129 loss: 0.9437554945267417 star(s) out of 5\nepoch: 130 loss: 0.9408376779822724 star(s) out of 5\nepoch: 131 loss: 0.9426214706281465 star(s) out of 5\nepoch: 132 loss: 0.9402632326535721 star(s) out of 5\nepoch: 133 loss: 0.9417516743215313 star(s) out of 5\nepoch: 134 loss: 0.9394916650837342 star(s) out of 5\nepoch: 135 loss: 0.941021001402803 star(s) out of 5\nepoch: 136 loss: 0.9384383022035268 star(s) out of 5\nepoch: 137 loss: 0.9403459768498744 star(s) out of 5\nepoch: 138 loss: 0.9378946043115808 star(s) out of 5\nepoch: 139 loss: 0.9397742588140435 star(s) out of 5\nepoch: 140 loss: 0.937295731745981 star(s) out of 5\nepoch: 141 loss: 0.9392710990699759 star(s) out of 5\nepoch: 142 loss: 0.9367356127034219 star(s) out of 5\nepoch: 143 loss: 0.9388057776400796 star(s) out of 5\nepoch: 144 loss: 0.9362373372089587 star(s) out of 5\nepoch: 145 loss: 0.9381660988290684 star(s) out of 5\nepoch: 146 loss: 0.9354213768162541 star(s) out of 5\nepoch: 147 loss: 0.9376929906135913 star(s) out of 5\nepoch: 148 loss: 0.9349235459603421 star(s) out of 5\nepoch: 149 loss: 0.9370786689339784 star(s) out of 5\nepoch: 150 loss: 0.9342257130265187 star(s) out of 5\nepoch: 151 loss: 0.936593745332381 star(s) out of 5\nepoch: 152 loss: 0.9338395607864061 star(s) out of 5\nepoch: 153 loss: 0.9360114938454785 star(s) out of 5\nepoch: 154 loss: 0.9332396310227872 star(s) out of 5\nepoch: 155 loss: 0.9353655381662517 star(s) out of 5\nepoch: 156 loss: 0.9326383837549017 star(s) out of 5\nepoch: 157 loss: 0.9350185307187676 star(s) out of 5\nepoch: 158 loss: 0.9322959337018819 star(s) out of 5\nepoch: 159 loss: 0.9345876393089553 star(s) out of 5\nepoch: 160 loss: 0.9319820742295544 star(s) out of 5\nepoch: 161 loss: 0.9340803713738738 star(s) out of 5\nepoch: 162 loss: 0.9314017673870337 star(s) out of 5\nepoch: 163 loss: 0.9334649829192164 star(s) out of 5\nepoch: 164 loss: 0.9307407602943131 star(s) out of 5\nepoch: 165 loss: 0.9330902570228239 star(s) out of 5\nepoch: 166 loss: 0.930381413107243 star(s) out of 5\nepoch: 167 loss: 0.9326251190077618 star(s) out of 5\nepoch: 168 loss: 0.929801867757907 star(s) out of 5\nepoch: 169 loss: 0.9319282153008189 star(s) out of 5\nepoch: 170 loss: 0.9294597485874637 star(s) out of 5\nepoch: 171 loss: 0.9316257699364582 star(s) out of 5\nepoch: 172 loss: 0.9289910090236098 star(s) out of 5\nepoch: 173 loss: 0.931356200633846 star(s) out of 5\nepoch: 174 loss: 0.9285781508493898 star(s) out of 5\nepoch: 175 loss: 0.9306454667771501 star(s) out of 5\nepoch: 176 loss: 0.9282504815746218 star(s) out of 5\nepoch: 177 loss: 0.9305146509835313 star(s) out of 5\nepoch: 178 loss: 0.9276494474372667 star(s) out of 5\nepoch: 179 loss: 0.93010343571451 star(s) out of 5\nepoch: 180 loss: 0.9274457392984831 star(s) out of 5\nepoch: 181 loss: 0.9299420433624206 star(s) out of 5\nepoch: 182 loss: 0.926881065299703 star(s) out of 5\nepoch: 183 loss: 0.9293260837721352 star(s) out of 5\nepoch: 184 loss: 0.9267192350891689 star(s) out of 5\nepoch: 185 loss: 0.9291491196580174 star(s) out of 5\nepoch: 186 loss: 0.926184980147408 star(s) out of 5\nepoch: 187 loss: 0.9287223240435951 star(s) out of 5\nepoch: 188 loss: 0.9259078931689771 star(s) out of 5\nepoch: 189 loss: 0.9285104380429574 star(s) out of 5\nepoch: 190 loss: 0.9254375749787772 star(s) out of 5\nepoch: 191 loss: 0.928027382055784 star(s) out of 5\nepoch: 192 loss: 0.92519530588532 star(s) out of 5\nepoch: 193 loss: 0.9276371725860617 star(s) out of 5\nepoch: 194 loss: 0.924922203015929 star(s) out of 5\nepoch: 195 loss: 0.9272516846746083 star(s) out of 5\nepoch: 196 loss: 0.9245886914520087 star(s) out of 5\nepoch: 197 loss: 0.9270367924862374 star(s) out of 5\nepoch: 198 loss: 0.924243788963745 star(s) out of 5\nepoch: 199 loss: 0.9266688851466303 star(s) out of 5\nepoch: 200 loss: 0.9240191308665342 star(s) out of 5\n"
    }
   ],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    training_loss = 0\n",
    "    s = 0.\n",
    "    for user in range(total_users):\n",
    "        input = Variable(training_set[user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.requires_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = total_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            training_loss += np.sqrt(loss.data.item() * mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch:', epoch + 1, 'loss:', training_loss / s, 'star(s) out of 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing the Auto Encoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss on Test Set: 0.9638131935324882 star(s) out of 5\n"
    }
   ],
   "source": [
    "\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for user in range(total_users):\n",
    "    input = Variable(training_set[user]).unsqueeze(0)\n",
    "    target = Variable(test_set[user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.requires_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = total_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data.item() * mean_corrector)\n",
    "        s += 1.\n",
    "print('Loss on Test Set:', test_loss / s, 'star(s) out of 5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}