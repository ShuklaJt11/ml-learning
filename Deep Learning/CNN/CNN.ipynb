{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (128, 128)\n",
    "batch= 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training Set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size=img_size, # try with 150, 150 later\n",
    "    batch_size=batch,\n",
    "    class_mode='binary',\n",
    "    seed=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test Set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size=img_size, # try with 150, 150 later\n",
    "    batch_size=batch,\n",
    "    class_mode='binary',\n",
    "    seed=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Initializing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Convolution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[img_size[0], img_size[1], 3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pooling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn.add(tf.keras.layers.Dropout(0.2, seed=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adding a second convolutional Layer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "#cnn.add(tf.keras.layers.Dropout(0.2, seed=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Flattening*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Full Connection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "#cnn.add(tf.keras.layers.Dropout(0.25, seed=11))\n",
    "cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "#cnn.add(tf.keras.layers.Dropout(0.25, seed=11)) #Later on try with 2-3 Layers including dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Compiling the CNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               27558400  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 27,656,865\n",
      "Trainable params: 27,656,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the CNN on Training set and evaluating it on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 125 steps, validate for 32 steps\n",
      "Epoch 1/1000\n",
      "125/125 [==============================] - 65s 523ms/step - loss: 0.7044 - accuracy: 0.5332 - val_loss: 0.6741 - val_accuracy: 0.6280\n",
      "Epoch 2/1000\n",
      "125/125 [==============================] - 62s 494ms/step - loss: 0.6732 - accuracy: 0.5932 - val_loss: 0.6745 - val_accuracy: 0.6150\n",
      "Epoch 3/1000\n",
      "125/125 [==============================] - 62s 494ms/step - loss: 0.6411 - accuracy: 0.6388 - val_loss: 0.6107 - val_accuracy: 0.6820\n",
      "Epoch 4/1000\n",
      "125/125 [==============================] - 63s 500ms/step - loss: 0.6106 - accuracy: 0.6655 - val_loss: 0.5957 - val_accuracy: 0.6920\n",
      "Epoch 5/1000\n",
      "125/125 [==============================] - 61s 487ms/step - loss: 0.5948 - accuracy: 0.6779 - val_loss: 0.5773 - val_accuracy: 0.6985\n",
      "Epoch 6/1000\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.5698 - accuracy: 0.7063 - val_loss: 0.5685 - val_accuracy: 0.7135\n",
      "Epoch 7/1000\n",
      "125/125 [==============================] - 60s 478ms/step - loss: 0.5381 - accuracy: 0.7246 - val_loss: 0.5306 - val_accuracy: 0.7430\n",
      "Epoch 8/1000\n",
      "125/125 [==============================] - 62s 497ms/step - loss: 0.5142 - accuracy: 0.7406 - val_loss: 0.5065 - val_accuracy: 0.7610\n",
      "Epoch 9/1000\n",
      "125/125 [==============================] - 62s 496ms/step - loss: 0.4916 - accuracy: 0.7676 - val_loss: 0.4737 - val_accuracy: 0.7845\n",
      "Epoch 10/1000\n",
      "125/125 [==============================] - 63s 506ms/step - loss: 0.4663 - accuracy: 0.7772 - val_loss: 0.4603 - val_accuracy: 0.7975\n",
      "Epoch 11/1000\n",
      "125/125 [==============================] - 65s 519ms/step - loss: 0.4509 - accuracy: 0.7895 - val_loss: 0.4896 - val_accuracy: 0.7660\n",
      "Epoch 12/1000\n",
      "125/125 [==============================] - 62s 498ms/step - loss: 0.4482 - accuracy: 0.7810 - val_loss: 0.4592 - val_accuracy: 0.7875\n",
      "Epoch 13/1000\n",
      "125/125 [==============================] - 63s 504ms/step - loss: 0.4369 - accuracy: 0.7945 - val_loss: 0.4148 - val_accuracy: 0.8170\n",
      "Epoch 14/1000\n",
      "125/125 [==============================] - 62s 496ms/step - loss: 0.4240 - accuracy: 0.7984 - val_loss: 0.4344 - val_accuracy: 0.8165\n",
      "Epoch 15/1000\n",
      "125/125 [==============================] - 63s 501ms/step - loss: 0.4094 - accuracy: 0.8115 - val_loss: 0.4134 - val_accuracy: 0.8210\n",
      "Epoch 16/1000\n",
      "125/125 [==============================] - 62s 494ms/step - loss: 0.3931 - accuracy: 0.8176 - val_loss: 0.4605 - val_accuracy: 0.8290\n",
      "Epoch 17/1000\n",
      "125/125 [==============================] - 63s 504ms/step - loss: 0.3878 - accuracy: 0.8213 - val_loss: 0.4386 - val_accuracy: 0.8070\n",
      "Epoch 18/1000\n",
      "125/125 [==============================] - 65s 517ms/step - loss: 0.3748 - accuracy: 0.8309 - val_loss: 0.3851 - val_accuracy: 0.8280\n",
      "Epoch 19/1000\n",
      "125/125 [==============================] - 64s 509ms/step - loss: 0.3685 - accuracy: 0.8322 - val_loss: 0.3895 - val_accuracy: 0.8385\n",
      "Epoch 20/1000\n",
      "125/125 [==============================] - 65s 520ms/step - loss: 0.3734 - accuracy: 0.8316 - val_loss: 0.3557 - val_accuracy: 0.8445\n",
      "Epoch 21/1000\n",
      "125/125 [==============================] - 64s 513ms/step - loss: 0.3470 - accuracy: 0.8478 - val_loss: 0.3718 - val_accuracy: 0.8480\n",
      "Epoch 22/1000\n",
      "125/125 [==============================] - 64s 508ms/step - loss: 0.3353 - accuracy: 0.8494 - val_loss: 0.4039 - val_accuracy: 0.8265\n",
      "Epoch 23/1000\n",
      "125/125 [==============================] - 59s 471ms/step - loss: 0.3300 - accuracy: 0.8536 - val_loss: 0.3533 - val_accuracy: 0.8545\n",
      "Epoch 24/1000\n",
      "125/125 [==============================] - 60s 476ms/step - loss: 0.3293 - accuracy: 0.8545 - val_loss: 0.3663 - val_accuracy: 0.8540\n",
      "Epoch 25/1000\n",
      "125/125 [==============================] - 58s 461ms/step - loss: 0.3250 - accuracy: 0.8583 - val_loss: 0.3922 - val_accuracy: 0.8380\n",
      "Epoch 26/1000\n",
      "125/125 [==============================] - 59s 468ms/step - loss: 0.3186 - accuracy: 0.8643 - val_loss: 0.3694 - val_accuracy: 0.8435\n",
      "Epoch 27/1000\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.3011 - accuracy: 0.8719 - val_loss: 0.3368 - val_accuracy: 0.8675\n",
      "Epoch 28/1000\n",
      "125/125 [==============================] - 58s 468ms/step - loss: 0.2921 - accuracy: 0.8711 - val_loss: 0.3210 - val_accuracy: 0.8635\n",
      "Epoch 29/1000\n",
      "125/125 [==============================] - 59s 475ms/step - loss: 0.2993 - accuracy: 0.8701 - val_loss: 0.3910 - val_accuracy: 0.8455\n",
      "Epoch 30/1000\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.2860 - accuracy: 0.8802 - val_loss: 0.3310 - val_accuracy: 0.8740\n",
      "Epoch 31/1000\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.2791 - accuracy: 0.8792 - val_loss: 0.3177 - val_accuracy: 0.8735\n",
      "Epoch 32/1000\n",
      "125/125 [==============================] - 59s 476ms/step - loss: 0.2697 - accuracy: 0.8841 - val_loss: 0.3551 - val_accuracy: 0.8535\n",
      "Epoch 33/1000\n",
      "125/125 [==============================] - 59s 475ms/step - loss: 0.2657 - accuracy: 0.8889 - val_loss: 0.3211 - val_accuracy: 0.8705\n",
      "Epoch 34/1000\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.2568 - accuracy: 0.8926 - val_loss: 0.4225 - val_accuracy: 0.8215\n",
      "Epoch 35/1000\n",
      "125/125 [==============================] - 58s 464ms/step - loss: 0.2588 - accuracy: 0.8915 - val_loss: 0.3276 - val_accuracy: 0.8695\n",
      "Epoch 36/1000\n",
      "125/125 [==============================] - 60s 483ms/step - loss: 0.2482 - accuracy: 0.8970 - val_loss: 0.3144 - val_accuracy: 0.8735\n",
      "Epoch 37/1000\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.2378 - accuracy: 0.9016 - val_loss: 0.3092 - val_accuracy: 0.8815\n",
      "Epoch 38/1000\n",
      "125/125 [==============================] - 58s 466ms/step - loss: 0.2376 - accuracy: 0.9030 - val_loss: 0.3401 - val_accuracy: 0.8730\n",
      "Epoch 39/1000\n",
      "125/125 [==============================] - 59s 473ms/step - loss: 0.2269 - accuracy: 0.9024 - val_loss: 0.2948 - val_accuracy: 0.8875\n",
      "Epoch 40/1000\n",
      "125/125 [==============================] - 58s 465ms/step - loss: 0.2195 - accuracy: 0.9101 - val_loss: 0.3297 - val_accuracy: 0.8820\n",
      "Epoch 41/1000\n",
      "125/125 [==============================] - 58s 463ms/step - loss: 0.2273 - accuracy: 0.9059 - val_loss: 0.3104 - val_accuracy: 0.8900\n",
      "Epoch 42/1000\n",
      "125/125 [==============================] - 65s 516ms/step - loss: 0.2129 - accuracy: 0.9104 - val_loss: 0.3213 - val_accuracy: 0.8815\n",
      "Epoch 43/1000\n",
      "125/125 [==============================] - 64s 508ms/step - loss: 0.2143 - accuracy: 0.9091 - val_loss: 0.3089 - val_accuracy: 0.8795\n",
      "Epoch 44/1000\n",
      "125/125 [==============================] - 65s 520ms/step - loss: 0.2074 - accuracy: 0.9144 - val_loss: 0.3300 - val_accuracy: 0.8760\n",
      "Epoch 45/1000\n",
      "125/125 [==============================] - 60s 479ms/step - loss: 0.2095 - accuracy: 0.9156 - val_loss: 0.2976 - val_accuracy: 0.8910\n",
      "Epoch 46/1000\n",
      "125/125 [==============================] - 58s 462ms/step - loss: 0.1971 - accuracy: 0.9194 - val_loss: 0.3332 - val_accuracy: 0.8870\n",
      "Epoch 47/1000\n",
      "125/125 [==============================] - 58s 467ms/step - loss: 0.2016 - accuracy: 0.9184 - val_loss: 0.3349 - val_accuracy: 0.8900\n",
      "Epoch 48/1000\n",
      "125/125 [==============================] - 58s 461ms/step - loss: 0.1976 - accuracy: 0.9165 - val_loss: 0.3131 - val_accuracy: 0.8860\n",
      "Epoch 49/1000\n",
      "125/125 [==============================] - 60s 478ms/step - loss: 0.1883 - accuracy: 0.9229 - val_loss: 0.3110 - val_accuracy: 0.8860\n",
      "Epoch 50/1000\n",
      "125/125 [==============================] - 60s 477ms/step - loss: 0.1895 - accuracy: 0.9239 - val_loss: 0.3146 - val_accuracy: 0.8860\n",
      "Epoch 51/1000\n",
      "125/125 [==============================] - 58s 466ms/step - loss: 0.1909 - accuracy: 0.9234 - val_loss: 0.3116 - val_accuracy: 0.8885\n",
      "Epoch 52/1000\n",
      "125/125 [==============================] - 59s 476ms/step - loss: 0.1882 - accuracy: 0.9234 - val_loss: 0.4141 - val_accuracy: 0.8555\n",
      "Epoch 53/1000\n",
      "125/125 [==============================] - 60s 483ms/step - loss: 0.1796 - accuracy: 0.9299 - val_loss: 0.3040 - val_accuracy: 0.8860\n",
      "Epoch 54/1000\n",
      "125/125 [==============================] - 61s 485ms/step - loss: 0.1803 - accuracy: 0.9249 - val_loss: 0.3226 - val_accuracy: 0.8910\n",
      "Epoch 55/1000\n",
      "125/125 [==============================] - 58s 465ms/step - loss: 0.1836 - accuracy: 0.9259 - val_loss: 0.3259 - val_accuracy: 0.8830\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29a4a463bc8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set, validation_data=test_set, epochs=1000, callbacks=[early_stop], workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Making Single Prediction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = image.load_img(path='dataset/single_prediction/cat_or_dog_2.jpg', target_size=img_size)\n",
    "test_img = image.img_to_array(test_img)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "res = cnn.predict(test_img)\n",
    "if res[0][0] == 1:\n",
    "    pred = 'dog'\n",
    "else:\n",
    "    pred = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Result till now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image size: 128, 128\n",
    "- Batch Size: 64\n",
    "- NN Layers: (Conv(32, 3, relu) * 2 + MaxPool(2, 2)) + (Conv(64, 3, relu) * 2 + MaxPool(2, 2)) + Flatten() + (Dense(512, relu)) + (Dense(64, relu)) + Dense(1, sigmoid)\n",
    "- Early Stop: patience(10) + monitor(val_accuracy) + mode(max)\n",
    "- Fit: wrokers(8)\n",
    "- Total Epochs: 55 + best(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn.save('cat_or_dog_128_64_512_64_8910.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
