{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "- A tensor is any number, vector (1-D Array), matrix (2-D Array) or any n-D Array.\n",
    "- Tensors must have a **regular shape**.\n",
    "- All the elements in a tensor are of **same data type**. If different data type elements are given type casting is done in upward direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(5.)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.float32"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.tensor([1., 2., 3., 4., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.tensor([[5., 6], [7, 6], [8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = torch.Tensor([[[11, 12, 13], [14, 15, 16]], [[17, 18, 19.], [20, 21, 22]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.float32 torch.float32 torch.float32\n"
    }
   ],
   "source": [
    "print(t2.dtype, t3.dtype, t4.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 2., 3., 4., 5.])\ntensor([[5., 6.],\n        [7., 6.],\n        [8., 9.]])\ntensor([[[11., 12., 13.],\n         [14., 15., 16.]],\n\n        [[17., 18., 19.],\n         [20., 21., 22.]]])\n"
    }
   ],
   "source": [
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape\nT1: torch.Size([]) T2: torch.Size([5]) T3: torch.Size([3, 2]) T4: torch.Size([2, 2, 3])\n"
    }
   ],
   "source": [
    "print('Shape')\n",
    "print('T1:', t1.shape, 'T2:', t2.shape, 'T3:', t3.shape, 'T4:', t4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(17., grad_fn=<AddBackward0>)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once calculation is done. We can use `backward()` function to calculate devative of y w.r.t tensors that have `requires_grad` set to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dy/dx: None dy/dw: tensor(3.) dy/db: tensor(1.)\n"
    }
   ],
   "source": [
    "print('dy/dx:', x.grad, 'dy/dw:', w.grad, 'dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interoperability with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 2.],\n       [3., 4.]])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 2.],\n        [3., 4.]], dtype=torch.float64)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `from_numpy()` uses the same memory location as numpy array, whereas `tensor()` funtion create a copy within the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(dtype('float64'), torch.float64)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 2.],\n       [3., 4.]])"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major difference in a Torch Tensor and NumPy Array is the Torch Tensor are designed specifically to run **optimized operations on GPUs** whereas NumPy uses the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "l = torch.tensor(6.)\n",
    "m = torch.tensor(7., requires_grad=True)\n",
    "c = torch.tensor(8.)\n",
    "d = torch.tensor(9., requires_grad=True)\n",
    "y = w * x + b\n",
    "z = l * y + m\n",
    "w = c * z + d\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "None None tensor(1.)\n"
    }
   ],
   "source": [
    "print(x.grad, w.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(881., grad_fn=<AddBackward0>)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "y = torch.tensor([\n",
    "    [\n",
    "        [w * b, b + x],\n",
    "        [x - b, x * w]\n",
    "    ],\n",
    "    [\n",
    "        [x + w, b * x],\n",
    "        [x - w, b - w]\n",
    "    ]\n",
    "], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][0][0].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(None, None)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [1., 2.],\n",
    "    [3., 4.],\n",
    "    [5., 6.]\n",
    "])\n",
    "w = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "], requires_grad=True)\n",
    "b = torch.tensor(7., requires_grad=True)\n",
    "y = x * w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][0].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(None,\n tensor([[1., 0., 0.],\n         [0., 0., 0.]]),\n tensor(1.))"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "x.grad, w.grad, b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Never iterate over tensors. Always, try to find tensor operation as it will be faster to process than vanilla python loops"
   ]
  }
 ]
}