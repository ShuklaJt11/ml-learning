{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: MNIST dataset using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='dataset/', download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_pct):\n",
    "    n_val = int(val_pct * n)\n",
    "    idxs = np.random.permutation(n)\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(48000, 12000)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_idxs, val_idxs = split_indices(len(dataset), val_pct=0.2)\n",
    "\n",
    "len(train_idxs), len(val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idxs)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(val_idxs)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel (nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.full_connecton_1 = nn.Linear(in_size, hidden_size[0])\n",
    "        self.full_connecton_2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.full_connecton_3 = nn.Linear(hidden_size[1], out_size)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        out = F.relu(self.full_connecton_1(xb))\n",
    "        out = F.relu(self.full_connecton_2(out))\n",
    "        out = self.full_connecton_3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size = [256, 32]\n",
    "out_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel(input_size, hidden_size, out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([256, 784])\ntorch.Size([256])\ntorch.Size([32, 256])\ntorch.Size([32])\ntorch.Size([10, 32])\ntorch.Size([10])\n"
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "images.shape: torch.Size([128, 1, 28, 28])\nloss 2.310922384262085\noutputs.shape torch.Size([128, 10])\nSample outputs:\n tensor([[ 0.0578,  0.1278, -0.1149,  0.2035, -0.0403, -0.0136, -0.0651,  0.0116,\n          0.1817,  0.0012],\n        [ 0.0448,  0.1191, -0.0909,  0.1975, -0.0002, -0.0284, -0.0627, -0.0075,\n          0.2119, -0.0202]])\n"
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images.shape:', images.shape)\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print('loss', loss.item())\n",
    "    break\n",
    "\n",
    "print('outputs.shape', outputs.shape)\n",
    "print('Sample outputs:\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([128, 1, 28, 28])\ncuda:0\n"
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader:\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\ntensor([4, 8, 9, 9, 1, 1, 5, 5, 2, 2, 5, 4, 2, 7, 1, 4, 2, 8, 6, 2, 7, 4, 5, 1,\n        5, 7, 9, 9, 9, 3, 2, 2, 1, 4, 8, 3, 2, 2, 9, 1, 0, 7, 8, 0, 1, 3, 1, 9,\n        7, 5, 0, 2, 7, 8, 9, 5, 7, 3, 8, 6, 3, 6, 3, 9, 9, 7, 4, 6, 1, 3, 8, 7,\n        9, 5, 3, 1, 7, 5, 1, 7, 7, 4, 2, 3, 3, 7, 2, 5, 7, 5, 6, 6, 9, 0, 1, 1,\n        1, 2, 2, 1, 0, 2, 2, 7, 6, 4, 7, 9, 5, 5, 1, 3, 9, 9, 4, 5, 3, 7, 8, 0,\n        5, 9, 9, 5, 5, 8, 1, 3], device='cuda:0')\n"
    }
   ],
   "source": [
    "for xb, yb in val_loader:\n",
    "    print(xb.device)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        metric_result = metric(preds, yb)\n",
    "    \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, loss_fn, train_dl, valid_dl, opt_fn=None, metric=None):\n",
    "    losses, metrics = [], []\n",
    "\n",
    "    if opt_fn is None: opt_fn = torch.optim.SGD\n",
    "    opt = opt_fn(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            loss, _, _ = loss_batch(model, loss_fn, xb, yb, opt)\n",
    "        \n",
    "        result = evaluate(model, loss_fn, valid_dl, metric)\n",
    "        val_loss, total, val_metric = result\n",
    "\n",
    "        losses.append(val_loss)\n",
    "        metrics.append(val_metric)\n",
    "\n",
    "        if metric is None:\n",
    "            print('Epoch [{}/{}], Loss: {:.5f}'.format(epoch + 1, epochs, val_loss))\n",
    "        else:\n",
    "            print('Epoch [{}/{}], Loss: {:.5f}, {}: {:.5f}'.format(epoch + 1, epochs, val_loss, metric.__name__, val_metric))\n",
    "    \n",
    "    return losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}